---
title: "Tipología y ciclo de vida de los datos. Práctica 2"
author: "Mateo Rodríguez Lavado y Eduard Conesa Guerrero"
date: "20/12/2021"
output: 
  html_document:
    highlight: default
    number_sections: yes
    theme: cosmo
    toc: yes
    toc_depth: 2
---

******
# Descripción del dataset
******
Es conocido por muchos que el 15 de abril de 1912, durante una travesía por mar,
el Titanic se hundió tras chocar contra un iceberg en su viaje inaugural. Debido a
que no había botes salvavidas para todos los tripulantes, murieron muchos de ellos.

Este dataset contiene información sobre los pasajeros que iban a bordo del Titanic.
La información que contiene es la siguiente:

* PassengerId. Identificador del pasajero.
* survival.	Indica si el pasajero sobrevivió o no (0 = No, 1 = Si).
* pclass. Tipo de clase del ticket (1 = primera, 2 = segunda, 3 = tercera).
* sex. Sexo	
* Age. Años del pasajero.	
* sibsp. Número de hermanos o cónyuges a bordo del titanic.	
* parch. Numero de padres o hijos a borod del titanic.	
* ticket. Número del Ticket	
* fare. Tarifa para el pasajero.	
* cabin. Número de cabina.	
* embarked. Puerto de embarque.

Este dataset puede ayudar a estudiar esta catástrofe y así reducir el número de víctimas
en accidentes similares. La pregunta que intentamos responder es la siguiente: 
¿Qué tipo de personas tenían más probabilidades de sobrevivir?

El dataset lo leemos de la siguientes forma:

```{r,eval=TRUE,echo=FALSE,results='hide'}
defaultW <- getOption("warn") 
options(warn = -1)
```


```{r,eval=TRUE,echo=TRUE,results='hide',message=FALSE}
# Cargamos los paquetes R que vamos a usar
library(ggplot2)
library(dplyr)
library(VIM)
library(car)
```

```{r,eval=TRUE,echo=FALSE,results='hide'}
options(warn = defaultW)
```

```{r,eval=TRUE,echo=TRUE}
# Cargamos el fichero de datos
people<-read.csv("train.csv")

# Verificamos la estructura del conjunto de datos
str(people)
```

Se compone de un total de 891 personas que iban a bordo del titanic. Le echamos 
un rápido vistazo a las variables para ver un resumen de las mismas.

```{r,eval=TRUE,echo=TRUE}
summary(people)
```

******
# Integración y selección de los datos de interés a analizar
******
Despues de describir los campos mostrados en el apartado anterior, se realiza una selección de los atributos de interés para cuando se deseen realizar los diferentes modelos.

Por una parte, los atributos de PassengerId y Name son atributos que solo identifican a la persona, con lo que no aportan información relevante de la supervivencia. Por otra parte el atributo Cabin presenta un gran numero de campos vacios con lo que tampoco se tendrá en cuenta.

```{r,eval=TRUE,echo=TRUE}
people_red<-people[,c("Survived", "Pclass", "Sex", "Age", "SibSp", "Parch", "Ticket", "Fare", "Embarked")]
```

Si nos fijamos en los registros obtenidos, existen dos pasajeros que no disponen de valor de "Embarked" con lo que se eliminaran dichos registros, ya que según se puede observar son dos personas relacionadas que probablemente no subiran a bordo y por tanto no es relevante esta información para estimar la supervivencia de los pasajeros que si lo hicieron.

```{r,eval=TRUE,echo=TRUE}
people$Survived[which(people$Embarked == "")]
people_red <- people_red[people_red$Embarked != "", ]
```


Se decide estudiar si se puede generar un nuevo campo con las letras que en ocasiones contiene el ticket.
```{r,eval=TRUE,echo=TRUE}
num_Ticket<-as.numeric(people_red$Ticket)
sum(is.na(num_Ticket))
length(num_Ticket)
```

Como se observa, hay muchos registros que no disponen de letras (un 25% aproximadamente), por lo que se descarte generar un campo solo para las letras. 

A continuación se estudia si las letras tambien son utiles para la identificación del ticket o basta con los numeros.
```{r,eval=TRUE,echo=TRUE}
people_red$TicketNum <- sapply(strsplit(people_red$Ticket, " ", fixed=TRUE), tail, 1)
head(people_red)
length(unique(people_red$TicketNum))
length(unique(people_red$Ticket))
```

Dado que hay un variación de 2 entre los valores unicos del ticket con letra respecto al ticket sin letra se decide no simplificarlo de manera numerica, ya que es necesaria tambien.
```{r,eval=TRUE,echo=TRUE}
people_red$TicketNum <- NULL
```

******
# Limpieza de los datos
******

## Elementos vacíos
A continuación se estudian los campos que presentan valores vacios o nulos.
```{r,eval=TRUE,echo=TRUE}
colSums(is.na(people))
colSums(people==-1)
colSums(people=="")
colSums(is.na(people_red))
```

Como se ha comentado antes, al haber gran cantidad de registros con Cabin vacio, este atributo ha sido eliminado en la fase anterior, asi como tambien los dos registros con Embarked vacio.

Por otra parte se observa que el atributo de edad tiene 177 registros sin valor, igual que en la version reducida del dataset, probablemente porque sea desconocido. Se pueden imputar los valores utilizando por ejemplo el algoritmo de vecinos cercanos basado en la distancia tomando en cuenta las variables Pclass, Fare, SibSp, Parch. Son de especial utilidad las ultimas variables, ya que contienen información en cuanto a los familiares, lo que nos puede indicar si esa persona es mayor o joven.

```{r,eval=TRUE,echo=TRUE}
people_red <- kNN(people_red , variable=c("Age"), dist_var=c("Pclass","SibSp", "Parch", "Fare"))
sum(is.na(people_red$Age))
```

Como se observa ya se han imputado los valores ausentes del atributo Age. Se elimina tambien el ultimo campo añadido al dataset que contiene la información de valores imputados.
```{r,eval=TRUE,echo=TRUE}
people_red$Age_imp <- NULL
```

## Valores extremos

Los valores extremos solo los podemos ver en las variables numéricas que en este
caso son Age y Fare.

Empezaremos por la variable Age. Para comprobar los valores extremos haremos un
diagrama de caja que muestre si existen estos valores porque tienen una diferencia mayor
a tres veces la desviación típica respecto la media. 

```{r echo=TRUE, message=FALSE, warning=FALSE}
# Boxplot

bpAge <-boxplot(people_red$Age)
sort(boxplot.stats(people_red$Age)$out)
```

Los valores que nos salen outliers son personas mayores que 64 años, siendo su
máximo 80, pero esto son valores normales dentro de la edad de una persona por lo
que no se realiza ningún tratamiento especial.

Si realizamos lo mismo para la variables Fare tenemos:
```{r echo=TRUE, message=FALSE, warning=FALSE}
# Boxplot

bpFare <-boxplot(people_red$Fare)
sort(bpFare$out)
```

Lo más lógico es que todos estos precios altos correspondieran a billetes de
primera clase muy selectos o a subidas de precio debido a la oferta y demanda.
Lo primero que vamos a ver es como se distribuyen estos billetes según la clase.

```{r echo=TRUE, message=FALSE, warning=FALSE}
people_red_outFare <- people_red[people_red$Fare %in% bpFare$out,]
class <- c("1a","2a","3a")
freq_pclass_outFare <- as.data.frame(table(people_red_outFare$Pclass))
ggplot(freq_pclass_outFare,aes(x=Var1,y=Freq, fill=class))+geom_bar(stat = "identity", position = "dodge") + labs(x="Pclass")+ggtitle("Distribución de precio segun clase de los outliers")
```

Comparando con la distribución original:

```{r echo=TRUE, message=FALSE, warning=FALSE}
freq_pclass <- as.data.frame(table(people_red$Pclass)) 
ggplot(freq_pclass,aes(x=Var1,y=Freq, fill=class))+geom_bar(stat = "identity", position = "dodge") + labs(x="Pclass")+ggtitle("Distribución de precio segun clase")
```

Observamos que la mitad de los pasajeros de primera clase tienen precios mayores
de lo esperado. Sin embargo, para las clases segunda y tercera hay muy poco que tengan outliers por lo tanto podremos reemplazar sus valores por la media del
valor del ticket por cada clase.

```{r echo=TRUE, message=FALSE, warning=FALSE}
#Cojo solo los valores que no sean outliers y calculo la media
people_red_wo_out <- people_red[!(people_red$Fare %in% bpFare$out),]
mean_class <- aggregate(people_red_wo_out$Fare, list(people_red_wo_out$Pclass), mean)
colnames(mean_class) <- c("Pclass", "mean")
#Sustituyo para la clase 2
people_red[(people_red$Fare %in% bpFare$out) & (people_red$Pclass == 2),]$Fare <- mean_class[mean_class$Pclass == 2,]$mean
#Sustituyo para la clase 3
people_red[(people_red$Fare %in% bpFare$out) & (people_red$Pclass == 3),]$Fare <- mean_class[mean_class$Pclass == 3,]$mean
```

Si nos fijamos otra vez en el diagrama de cajas observamos que hay una separación grande entre tickets con valor menor que 200 y mayor que 200, por lo tanto, estos valores también los sustituiremos con la media

```{r echo=TRUE, message=FALSE, warning=FALSE}
#Sustituyo para la clase 1
people_red[(people_red$Fare %in% bpFare$out) & (people_red$Pclass == 1) & (people_red$Fare >= 200),]$Fare <- mean_class[mean_class$Pclass == 1,]$mean
```

Por ultimo se convierten las clases con valor categorico a factor, para su correcto procesado posterior.
```{r echo=TRUE, message=FALSE, warning=FALSE}
people_red$Sex <- as.factor(people_red$Sex)
people_red$Pclass <- as.factor(people_red$Pclass)
people_red$Embarked <- as.factor(people_red$Embarked)
people_red$Survived <- as.factor(people_red$Survived)
people_red$Ticket <- as.factor(people_red$Ticket)
```

******
# Análisis de los datos.
******

## Selección de los grupos de datos

A continuación, Vamos a seleccionar de nuestro conjunto de datos aquellos que pueden resultar más interesantes para investigar y analizar.

```{r echo=TRUE, message=FALSE, warning=FALSE}
#Agrupación por sexo
people_red.male <- people_red[people_red$Sex == "male",]
people_red.female <- people_red[people_red$Sex == "female",]

#Agrupación por embarque
people_red.cherbourg <- people_red[people_red$Embarked == "C",]
people_red.southampton <- people_red[people_red$Embarked == "S",]
people_red.queenstown <- people_red[people_red$Embarked == "Q",]

#Agrupación por clase
people_red.first <- people_red[people_red$Pclass == 1,]
people_red.second <- people_red[people_red$Pclass == 2,]
people_red.third <- people_red[people_red$Pclass == 3,]

```

## Comprobación de normalidad y homogeneidad

Miramos si la variables Fare y Age siguen una distribución normal. Para ello aplicamos el test de Shapiro-Wilk asi como se muestra tambien el grafico cuartil-cuartil.

```{r echo=TRUE, message=FALSE, warning=FALSE}
shapiro.test(people_red$Fare)
qqnorm(people_red$Fare)
qqline(people_red$Fare, col = "steelblue", lwd = 2)

shapiro.test(people_red$Age)
qqnorm(people_red$Age)
qqline(people_red$Age, col = "steelblue", lwd = 2)
```


Observamos que la distribución se aleja mucho de la distribución normal en el grafico. Esto se corrobora al ver que el p-valor es muy inferior a 0.05 y rechazamos la hipótesis nula. Por lo tanto, no podemos suponer normalidad en las variables. 

Ahora pasaremos a estudiar la homogeneidad de varianzas mediante la aplicación del test de Fligner-Kileen, ya que las variables no cumplen la condición de normalidad. Estudiaremos la homocedasticidad según varios grupos: la clase del pasajero (Pclass), el lugar de embarque (Embarked), edad (Age) y el sexo (Sex).

```{r echo=TRUE, message=FALSE, warning=FALSE}
fligner.test(Fare ~ as.factor(Age), data = people_red )
fligner.test(Fare ~ Pclass, data = people_red)
fligner.test(Fare ~ Embarked, data = people_red)
fligner.test(Fare ~ Sex, data = people_red)
```

Observamos que para las cuatro pruebas resulta un p-valor inferior al nivel de significancia (< 0,05). Por lo tanto, se rechaza la hipótesis nula de homocedasticidad y se concluye que la variable Fare presenta varianzas estadísticamente diferentes para los diferentes grupos de Pclass, Embarked, Age y Sex.


## Análisis

### Clustering

A continuación se desea observar si es posible obtener una caracterización de los supervivientes o pasajeros del Titanic, por lo que se aplica un metodo de clusterización basado en k-medoides, utilizando la distancia de Gower, que permite combinar atributos numericos con categóricos. Para hacer esta caracterización se tendrán en cuenta todos los atributos.
```{r echo=TRUE, message=FALSE, warning=FALSE}
library(cluster)

gower_dist <- daisy(people_red[ , -which(names(people_red) %in% c("Survived"))],
                    metric = "gower",
                    type = list(logratio = 3))
```

A continuación, se determina el número óptimo de grupos.
```{r echo=TRUE, message=FALSE, warning=FALSE}
sil_width <- c(NA)
for(i in 2:20){

  pam_fit <- pam(gower_dist,
                 diss = TRUE,
                 k = i)

  sil_width[i] <- pam_fit$silinfo$avg.width

}

# Plot sihouette width (higher is better)
plot(1:20, sil_width,
     xlab = "Number of clusters",
     ylab = "Silhouette Width")
lines(1:20, sil_width)
```

```{r echo=TRUE, message=FALSE, warning=FALSE}
pam_fit <- pam(gower_dist, diss = TRUE, k = 10)

pam_results <- people_red %>%
  dplyr::select(-Survived) %>%
  mutate(cluster = pam_fit$clustering) %>%
  group_by(cluster) %>%
  do(the_summary = summary(.))

# pam_results$the_summary

people_red[pam_fit$medoids, ]

people_red <- cbind(people_red, cluster = pam_fit$cluster)
pairs(people_red, col=c("red", "blue"))
```


```{r echo=TRUE, message=FALSE, warning=FALSE}
library(Rtsne) # for t-SNE plot
tsne_obj <- Rtsne(gower_dist, is_distance = TRUE)
tsne_data <- tsne_obj$Y %>%
  data.frame() %>%
  setNames(c("X", "Y")) %>%
  mutate(cluster = factor(pam_fit$clustering),
         name = people_red$Survived)
ggplot(aes(x = X, y = Y), data = tsne_data) +
  geom_point(aes(color = cluster))
```

### Arboles de decision

A continuación se generara un modelo para predecir los supervivientes mediante arboles de decisión. Para ello se seleccionan las variables comentadas anteriormente y se generan las muestras de test y validación.
```{r echo=TRUE, message=FALSE, warning=FALSE}
red_mod <- people_red[ ,c("Pclass", "SibSp", "Parch","Embarked", "Survived", "Age", "Fare", "Sex")]
s_size <- floor(0.75 * nrow(red_mod))

train_el <- sample(seq_len(nrow(red_mod)), size = s_size)

train <- red_mod[train_el, ]
test <- red_mod[-train_el, ]

```

Se genera el arbol de decisión con ctree y Random forest.
```{r echo=TRUE, message=FALSE, warning=FALSE}
library(rpart)
library(readr)
library(caTools)
library(party)
library(partykit)
library(rpart.plot)
library(caret)
# tree.survived <- rpart(Survived~.,data = train, method="class")
# plot(tree.survived)
# text(tree.survived, pretty = 0)

ctree_ <- ctree(Survived ~ ., train)
plot(ctree_)

library(randomForest)
forest.mod <- randomForest(Survived ~ ., data=red_mod, importance=TRUE,ntree=1000)
```

A continuación se realiza la predicción del modelo y se obtienen sus métricas.
```{r echo=TRUE, message=FALSE, warning=FALSE}
# tree.pred = predict(tree.survived, test, type="class")
# pred.results = with(tree.survived, table(tree.pred, test$Survived))
# confusionMatrix(pred.results,reference = test$Survived)

tree.pred.c = predict(ctree_, test, method="class")
pred.results.c = with(ctree_, table(tree.pred.c, test$Survived))
confusionMatrix(pred.results.c,reference = test$Survived)

forest.pred <- predict(forest.mod, red_mod, method="class")
pred.results.forest <- with(forest.mod, table(forest.pred, red_mod$Survived))
confusionMatrix(pred.results.forest, reference = red_mod$Survived)
```


### Contrastes
```{r echo=TRUE, message=FALSE, warning=FALSE}

t.test(people_red.first$Fare, people_red.second$Fare,alternative="greater", var.equal=FALSE)

t.test(people_red.second$Fare, people_red.third$Fare,alternative="greater", var.equal=FALSE)

t.test(people_red.first$Age, people_red.second$Age,alternative="greater", var.equal=FALSE)

t.test(people_red.first$Age, people_red.third$Age,alternative="greater", var.equal=FALSE)

t.test(people_red.third$SibSp, people_red.first$SibSp,alternative="greater", var.equal=FALSE)

t.test(people_red.third$SibSp, people_red.second$SibSp,alternative="greater", var.equal=FALSE)

```




******
# Conclusiones
******

******
# Tabla de contribuciones
******