---
title: "Tipología y ciclo de vida de los datos. Práctica 2"
author: "Mateo Rodríguez Lavado y Eduard Conesa Guerrero"
date: "20/12/2021"
output: 
  html_document:
    highlight: default
    number_sections: yes
    theme: cosmo
    toc: yes
    toc_depth: 2
---

******
# Descripción del dataset
******
Es conocido por muchos que el 15 de abril de 1912, durante una travesía por mar,
el Titanic se hundió tras chocar contra un iceberg en su viaje inaugural. Debido a
que no había botes salvavidas para todos los tripulantes, murieron muchos de ellos.

Este dataset contiene información sobre los pasajeros que iban a bordo del Titanic.
La información que contiene es la siguiente:
* PassengerId. Identificador del pasajero.
* survival.	Indica si el pasajero sobrevivió o no (0 = No, 1 = Si).
* pclass. Tipo de clase del ticket (1 = primera, 2 = segunda, 3 = tercera).
* sex. Sexo	
* Age. Años del pasajero.	
* sibsp. Número de hermanos o cónyuges a bordo del titanic.	
* parch. Numero de padres o hijos a borod del titanic.	
* ticket. Número del Ticket	
* fare. Tarifa para el pasajero.	
* cabin. Número de cabina.	
* embarked. Puerto de embarque.

Este dataset puede ayudar a estudiar esta catástrofe y así reducir el número de víctimas
en accidentes similares. La pregunta que intentamos responder es la siguiente: 
¿Qué tipo de personas tenían más probabilidades de sobrevivir?

El dataset lo leemos de la siguientes forma:

```{r,eval=TRUE,echo=FALSE,results='hide'}
defaultW <- getOption("warn") 
options(warn = -1)
```


```{r,eval=TRUE,echo=TRUE,results='hide',message=FALSE}
# Cargamos los paquetes R que vamos a usar
library(ggplot2)
library(dplyr)
library(VIM)
library(car)
library(caret)
```

```{r,eval=TRUE,echo=FALSE,results='hide'}
options(warn = defaultW)
```

```{r,eval=TRUE,echo=TRUE}
# Cargamos los ficheros de datos
people<-read.csv("train.csv")
test<-read.csv("test.csv")

# Verificamos la estructura del conjunto de datos
str(people)
```

Se compone de un total de 891 personas que iban a bordo del titanic. Le echamos 
un rápido vistazo a las variables para ver un resumen de las mismas.

```{r,eval=TRUE,echo=TRUE}
summary(people)
```

******
# Integración y selección de los datos de interés a analizar
******
Despues de describir los campos mostrados en el apartado anterior, se realiza una selección de los atributos de interés para cuando se deseen realizar los diferentes modelos.

Por una parte, los atributos de PassengerId y Name son atributos que solo identifican a la persona, con lo que no aportan información relevante de la supervivencia. Por otra parte el atributo Cabin presenta un gran numero de campos vacios con lo que tampoco se tendrá en cuenta.

```{r,eval=TRUE,echo=TRUE}
people_red<-people[,c("Survived", "Pclass", "Sex", "Age", "SibSp", "Parch", "Ticket", "Fare", "Embarked")]
test<-people[,c("Survived", "Pclass", "Sex", "Age", "SibSp", "Parch", "Ticket", "Fare", "Embarked")]
```

Si nos fijamos en los registros obtenidos, existen dos pasajeros que no disponen de valor de "Embarked" con lo que se eliminaran dichos registros, ya que según se puede observar son dos personas relacionadas que probablemente no subiran a bordo y por tanto no es relevante esta información para estimar la supervivencia de los pasajeros que si lo hicieron. También ocurre lo mismo con la información que nos viene en test.

```{r,eval=TRUE,echo=TRUE}
people$Survived[which(people$Embarked == "")]
people_red <- people_red[people_red$Embarked != "", ]
test$Survived[which(test$Embarked == "")]
test <- test[test$Embarked != "", ]
```


Se decide estudiar si se puede generar un nuevo campo con las letras que en ocasiones contiene el ticket.
```{r,eval=TRUE,echo=TRUE}
num_Ticket<-as.numeric(people_red$Ticket)
sum(is.na(num_Ticket))
length(num_Ticket)
```

Como se observa, hay muchos registros que no disponen de letras (un 25% aproximadamente), por lo que se descarte generar un campo solo para las letras. 

A continuación se estudia si las letras tambien son utiles para la identificación del ticket o basta con los numeros.
```{r,eval=TRUE,echo=TRUE}
people_red$TicketNum <- sapply(strsplit(people_red$Ticket, " ", fixed=TRUE), tail, 1)
head(people_red)
length(unique(people_red$TicketNum))
length(unique(people_red$Ticket))
```

Dado que hay un variación de 2 entre los valores unicos del ticket con letra respecto al ticket sin letra se decide no simplificarlo de manera numerica, ya que es necesaria tambien.

Al no encontrar utilidad en los campos de ticket, finalmente deciden no seleccionarse para el estudio.

```{r,eval=TRUE,echo=TRUE}
people_red$Ticket <- NULL
people_red$TicketNum <- NULL
test$Ticket <- NULL
```


******
# Limpieza de los datos
******

## Elementos vacíos
A continuación se estudian los campos que presentan valores vacios o nulos.
```{r,eval=TRUE,echo=TRUE}
colSums(is.na(people))
colSums(people==-1)
colSums(people=="")
colSums(is.na(people_red))
# totalData_crew["segmento_edad"] <- cut(totalData_crew$age, breaks = c(0,10,20,30,40,50,60,70,100), labels = c("0-9", "10-19", "20-29", "30-39","40-49","50-59","60-69","70-79"))
```

También lo hacemos con los datos de test
```{r,eval=TRUE,echo=TRUE}
colSums(test==-1)
colSums(test=="")
colSums(is.na(test))
```

Como se ha comentado antes, al haber gran cantidad de registros con Cabin vacio, este atributo ha sido eliminado en la fase anterior, asi como tambien los dos registros con Embarked vacio.

Por otra parte se observa que el atributo de edad tiene 177 registros sin valor, igual que en la version reducida del dataset, probablemente porque sea desconocido. En la parte de test se observa que tiene 86 registros sin valor en la variable edad y uno en la variable Fare. Se pueden imputar los valores utilizando por ejemplo el algoritmo de vecinos cercanos basado en la distancia tomando en cuenta las variables Pclass, Fare, SibSp, Parch. Son de especial utilidad las ultimas variables, ya que contienen información en cuanto a los familiares, lo que nos puede indicar si esa persona es mayor o joven.

```{r,eval=TRUE,echo=TRUE}
#Train
people_red <- kNN(people_red , variable=c("Age"), dist_var=c("Pclass","SibSp", "Parch", "Fare"))
sum(is.na(people_red$Age))

#Test
test <- kNN(test , variable=c("Fare"), dist_var=c("Pclass","SibSp", "Parch"))
test <- kNN(test , variable=c("Age"), dist_var=c("Pclass","SibSp", "Parch", "Fare"))
sum(is.na(test$Fare))
sum(is.na(test$Age))
```

Como se observa ya se han imputado los valores ausentes del atributo Age y Fare.

## Valores extremos

Los valores extremos solo los podemos ver en las variables numéricas que en este
caso son Age y Fare.

Empezaremos por la variable Age. Para comprobar los valores extremos haremos un
diagrama de caja que muestre si existen estos valores porque tienen una diferencia mayor
a tres veces la desviación típica respecto la media. 

```{r echo=TRUE, message=FALSE, warning=FALSE}
# Boxplot

bpAge <-boxplot(people_red$Age)
sort(boxplot.stats(people_red$Age)$out)
```

Los valores que nos salen outliers son personas mayores que 64 años, siendo su
máximo 80, pero esto son valores normales dentro de la edad de una persona por lo
que no se realiza ningún tratamiento especial.

Si realizamos lo mismo para la variables Fare tenemos:
```{r echo=TRUE, message=FALSE, warning=FALSE}
# Boxplot

bpFare <-boxplot(people_red$Fare)
sort(bpFare$out)
```

Lo más lógico es que todos estos precios altos correspondieran a billetes de
primera clase muy selectos o a subidas de precio debido a la oferta y demanda.
Lo primero que vamos a ver es como se distribuyen estos billetes según la clase.

```{r echo=TRUE, message=FALSE, warning=FALSE}
people_red_outFare <- people_red[people_red$Fare %in% bpFare$out,]
freq_pclass_outFare <- as.data.frame(table(people_red_outFare$Pclass))
ggplot(freq_pclass_outFare,aes(x=Var1,y=Freq))+geom_bar(stat = "identity", position = "dodge") + labs(x="Pclass")
```

Comparando con la distribución original:

```{r echo=TRUE, message=FALSE, warning=FALSE}
freq_pclass <- as.data.frame(table(people_red$Pclass)) 
ggplot(freq_pclass,aes(x=Var1,y=Freq))+geom_bar(stat = "identity", position = "dodge") + labs(x="Pclass")
```

Observamos que la mitad de los pasajeros de primera clase tienen precios mayores
de lo esperado. Sin embargo, para las clases segunda y tercera hay muy poco que tengan outliers por lo tanto podremos reemplazar sus valores por la media del
valor del ticket por cada clase.

```{r echo=TRUE, message=FALSE, warning=FALSE}
#Cojo solo los valores que no sean outliers y calculo la media
people_red_wo_out <- people_red[!(people_red$Fare %in% bpFare$out),]
mean_class <- aggregate(people_red_wo_out$Fare, list(people_red_wo_out$Pclass), mean)
colnames(mean_class) <- c("Pclass", "mean")
#Sustituyo para la clase 2
people_red[(people_red$Fare %in% bpFare$out) & (people_red$Pclass == 2),]$Fare <- mean_class[mean_class$Pclass == 2,]$mean
#Sustituyo para la clase 3
people_red[(people_red$Fare %in% bpFare$out) & (people_red$Pclass == 3),]$Fare <- mean_class[mean_class$Pclass == 3,]$mean
```

Si nos fijamos otra vez en el diagrama de cajas observamos que hay una separación grande entre tickets con valor menor que 200 y mayor que 200, por lo tanto, estos valores también los sustituiremos con la media

```{r echo=TRUE, message=FALSE, warning=FALSE}
#Sustituyo para la clase 1
people_red[(people_red$Fare %in% bpFare$out) & (people_red$Pclass == 1) & (people_red$Fare >= 200),]$Fare <- mean_class[mean_class$Pclass == 1,]$mean
```

******
# Análisis de los datos.
******

## Selección de los grupos de datos

A continuación, Vamos a seleccionar de nuestro conjunto de datos aquellos que pueden resultar más interesantes para investigar y analizar.

```{r echo=TRUE, message=FALSE, warning=FALSE}
#Agrupación por sexo
people_red.male <- people_red[people_red$Sex == "male",]
people_red.female <- people_red[people_red$Sex == "female",]

#Agrupación por embarque
people_red.cherbourg <- people_red[people_red$Embarked == "C",]
people_red.southampton <- people_red[people_red$Embarked == "S",]
people_red.queenstown <- people_red[people_red$Embarked == "Q",]

#Agrupación por clase
people_red.first <- people_red[people_red$Pclass == 1,]
people_red.second <- people_red[people_red$Pclass == 2,]
people_red.third <- people_red[people_red$Pclass == 3,]

```

## Comprobación de normalidad y homogeneidad

Miramos si la variable Fare sigue una distribución normal. Para ello aplicamos el test de Shapiro-Wilk.

```{r echo=TRUE, message=FALSE, warning=FALSE}
shapiro.test(people_red$Fare)
```

Observamos que el p-valor es muy inferior a 0.05 y rechazamos la hipótesis nula, por lo tanto, no podemos suponer normalidad en la variable. 

Ahora pasaremos a estudiar la homogeneidad de varianzas mediante la aplicación del test de Levenge. Estudiaremos la homocedasticidad según varios grupos: la clase del pasajero (Pclass), el lugar de embarque (Embarked) y el sexo (Sex).

```{r echo=TRUE, message=FALSE, warning=FALSE}
leveneTest(Fare ~ as.factor(Pclass), data = people_red)
leveneTest(Fare ~ as.factor(Embarked), data = people_red)
leveneTest(Fare ~ as.factor(Sex), data = people_red)
```

Observamos que para las tres pruebas resulta un p-valor inferior al nivel de significancia (< 0,05). Por lo tanto, se rechaza la hipótesis nula de homocedasticidad y se concluye que la variable Fare presenta varianzas estadísticamente diferentes para los diferentes grupos de Pclass, Embarked y Sex.

## Análisis

### Regresión Logística

En este caso, realizaremos una regresión logística para predecir nuestros datos. Para ello, lo primero que haremos será convertir la variable survived en un factor 0, 1 y la variable PClass en factor también. 

```{r echo=TRUE, message=FALSE, warning=FALSE}
people_red$Survived <- as.factor(people_red$Survived)
people_red$Pclass <- as.factor(people_red$Pclass)
test$Survived <- as.factor(test$Survived)
test$Pclass <- as.factor(test$Pclass)
str(people_red)
```

Ahora, vamos a aplicar una regresión logística utilizando todas las variables, tanto cuantitativas como cualitativas.

```{r echo=TRUE, message=FALSE, warning=FALSE}
logist = glm(formula=Survived ~ .,family=binomial, data = people_red)
summary(logist)
```

Podemos observar aquí como las variables de PClass, Sex, Age, SibSp y Parch son significativas ya que el p-valor proporcionado por el estadístico de Wald es inferior a 0,05. De estos regresores, vamos a ver cuál tiene mayor impacto. Para ello utilizamos el criterio de información de Akaike, es decir, observamos que valor tiene el AIC con cada una de las variables predictoras por separado.
```{r echo=TRUE, message=FALSE, warning=FALSE}
#Pclass
summary(glm(formula=Survived ~ Pclass,family=binomial, data = people_red))
#Sex
summary(glm(formula=Survived ~ Sex,family=binomial, data = people_red))
#Age
summary(glm(formula=Survived ~ Age,family=binomial, data = people_red))
#SibSp
summary(glm(formula=Survived ~ SibSp,family=binomial, data = people_red))
#Parch
summary(glm(formula=Survived ~ Parch,family=binomial, data = people_red))
```

Si comparamos los valores de AIC de cada modelo observamos que el de Sex es el mas bajo luego esa sera la variable más representativa.

Ahora predecimos el modelo con los valores de test y usamos un threshold para determinar si un resultado de la predicción es un 0 o un 1.

```{r echo=TRUE, message=FALSE, warning=FALSE}
pred<-predict(logist, test,type='response')
threshold <- ifelse(pred > 0.5, 1, 0)
p_class <- factor(threshold, levels = levels(test$Survived))
```

Por último, creamos la matriz de confusión para ver cuál es el valor predictivo de nuestro modelo.

```{r echo=TRUE, message=FALSE, warning=FALSE}
confusionMatrix(p_class, test$Survived)
```

Observamos que nuestro modelo tiene una precisión decente aunque mejorable. Por lo que parece, identifica bien los verdaderos positivos ya que tiene una sensibilidad alta.

******
# Conclusiones
******

******
# Tabla de contribuciones
******