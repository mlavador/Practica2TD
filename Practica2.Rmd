---
title: "Tipología y ciclo de vida de los datos. Práctica 2"
author: "Mateo Rodríguez Lavado y Eduard Conesa Guerrero"
date: "20/12/2021"
output: 
  html_document:
    highlight: default
    number_sections: yes
    theme: cosmo
    toc: yes
    toc_depth: 2
---

******
# Descripción del dataset
******
Es conocido por muchos que el 15 de abril de 1912, durante una travesía por mar,
el Titanic se hundió tras chocar contra un iceberg en su viaje inaugural. Debido a
que no había botes salvavidas para todos los tripulantes, murieron muchos de ellos.

Este dataset contiene información sobre los pasajeros que iban a bordo del Titanic.
La información que contiene es la siguiente:
* PassengerId. Identificador del pasajero.
* survival.	Indica si el pasajero sobrevivió o no (0 = No, 1 = Si).
* pclass. Tipo de clase del ticket (1 = primera, 2 = segunda, 3 = tercera).
* sex. Sexo	
* Age. Años del pasajero.	
* sibsp. Número de hermanos o cónyuges a bordo del titanic.	
* parch. Numero de padres o hijos a borod del titanic.	
* ticket. Número del Ticket	
* fare. Tarifa para el pasajero.	
* cabin. Número de cabina.	
* embarked. Puerto de embarque.

Este dataset puede ayudar a estudiar esta catástrofe y así reducir el número de víctimas
en accidentes similares. La pregunta que intentamos responder es la siguiente: 
¿Qué tipo de personas tenían más probabilidades de sobrevivir?

El dataset lo leemos de la siguientes forma:

```{r,eval=TRUE,echo=FALSE,results='hide'}
defaultW <- getOption("warn") 
options(warn = -1)
```


```{r,eval=TRUE,echo=TRUE,results='hide',message=FALSE}
# Cargamos los paquetes R que vamos a usar
library(ggplot2)
library(dplyr)
library(VIM)
library(car)
library(caret)
```

```{r,eval=TRUE,echo=FALSE,results='hide'}
options(warn = defaultW)
```

```{r,eval=TRUE,echo=TRUE}
# Cargamos los ficheros de datos
people<-read.csv("train.csv")

# Verificamos la estructura del conjunto de datos
str(people)
```

Se compone de un total de 891 personas que iban a bordo del titanic. Le echamos 
un rápido vistazo a las variables para ver un resumen de las mismas.

```{r,eval=TRUE,echo=TRUE}
summary(people)
```

******
# Integración y selección de los datos de interés a analizar
******
Despues de describir los campos mostrados en el apartado anterior, se realiza una selección de los atributos de interés para cuando se deseen realizar los diferentes modelos.

Por una parte, los atributos de PassengerId y Name son atributos que solo identifican a la persona, con lo que no aportan información relevante de la supervivencia. Por otra parte el atributo Cabin presenta un gran numero de campos vacios con lo que tampoco se tendrá en cuenta.

```{r,eval=TRUE,echo=TRUE}
people_red<-people[,c("Survived", "Pclass", "Sex", "Age", "SibSp", "Parch", "Ticket", "Fare", "Embarked")]
```

Si nos fijamos en los registros obtenidos, existen dos pasajeros que no disponen de valor de "Embarked" con lo que se eliminaran dichos registros, ya que según se puede observar son dos personas relacionadas que probablemente no subiran a bordo y por tanto no es relevante esta información para estimar la supervivencia de los pasajeros que si lo hicieron. 

```{r,eval=TRUE,echo=TRUE}
people$Survived[which(people$Embarked == "")]
people_red <- people_red[people_red$Embarked != "", ]
```


Se decide estudiar si se puede generar un nuevo campo con las letras que en ocasiones contiene el ticket.
```{r,eval=TRUE,echo=TRUE}
num_Ticket<-as.numeric(people_red$Ticket)
sum(is.na(num_Ticket))
length(num_Ticket)
```

Como se observa, hay muchos registros que no disponen de letras (un 25% aproximadamente), por lo que se descarte generar un campo solo para las letras. 

A continuación se estudia si las letras tambien son utiles para la identificación del ticket o basta con los numeros.
```{r,eval=TRUE,echo=TRUE}
people_red$TicketNum <- sapply(strsplit(people_red$Ticket, " ", fixed=TRUE), tail, 1)
head(people_red)
length(unique(people_red$TicketNum))
length(unique(people_red$Ticket))
```

Dado que hay un variación de 2 entre los valores unicos del ticket con letra respecto al ticket sin letra se decide no simplificarlo de manera numerica, ya que es necesaria tambien.

Al no encontrar utilidad en los campos de ticket, finalmente deciden no seleccionarse para el estudio.

```{r,eval=TRUE,echo=TRUE}
people_red$Ticket <- NULL
people_red$TicketNum <- NULL
```


******
# Limpieza de los datos
******

## Elementos vacíos
A continuación se estudian los campos que presentan valores vacios o nulos.
```{r,eval=TRUE,echo=TRUE}
colSums(is.na(people))
colSums(people==-1)
colSums(people=="")
colSums(is.na(people_red))
```

Como se ha comentado antes, al haber gran cantidad de registros con Cabin vacio, este atributo ha sido eliminado en la fase anterior, asi como tambien los dos registros con Embarked vacio.

Por otra parte se observa que el atributo de edad tiene 177 registros sin valor, igual que en la version reducida del dataset, probablemente porque sea desconocido. Se pueden imputar los valores utilizando por ejemplo el algoritmo de vecinos cercanos basado en la distancia tomando en cuenta las variables Pclass, Fare, SibSp, Parch. Son de especial utilidad las ultimas variables, ya que contienen información en cuanto a los familiares, lo que nos puede indicar si esa persona es mayor o joven.

```{r,eval=TRUE,echo=TRUE}
#Train
people_red <- kNN(people_red , variable=c("Age"), dist_var=c("Pclass","SibSp", "Parch", "Fare"))
sum(is.na(people_red$Age))
```

Como se observa ya se han imputado los valores ausentes del atributo Age y Fare.

## Valores extremos

Los valores extremos solo los podemos ver en las variables numéricas que en este
caso son Age y Fare.

Empezaremos por la variable Age. Para comprobar los valores extremos haremos un
diagrama de caja que muestre si existen estos valores porque tienen una diferencia mayor
a tres veces la desviación típica respecto la media. 

```{r echo=TRUE, message=FALSE, warning=FALSE}
# Boxplot

bpAge <-boxplot(people_red$Age)
sort(boxplot.stats(people_red$Age)$out)
```

Los valores que nos salen outliers son personas mayores que 64 años, siendo su
máximo 80, pero esto son valores normales dentro de la edad de una persona por lo
que no se realiza ningún tratamiento especial.

Si realizamos lo mismo para la variables Fare tenemos:
```{r echo=TRUE, message=FALSE, warning=FALSE}
# Boxplot

bpFare <-boxplot(people_red$Fare)
sort(bpFare$out)
```

Lo más lógico es que todos estos precios altos correspondieran a billetes de
primera clase muy selectos o a subidas de precio debido a la oferta y demanda.
Lo primero que vamos a ver es como se distribuyen estos billetes según la clase.

```{r echo=TRUE, message=FALSE, warning=FALSE}
people_red_outFare <- people_red[people_red$Fare %in% bpFare$out,]
freq_pclass_outFare <- as.data.frame(table(people_red_outFare$Pclass))
ggplot(freq_pclass_outFare,aes(x=Var1,y=Freq))+geom_bar(stat = "identity", position = "dodge") + labs(x="Pclass")
```

Comparando con la distribución original:

```{r echo=TRUE, message=FALSE, warning=FALSE}
freq_pclass <- as.data.frame(table(people_red$Pclass)) 
ggplot(freq_pclass,aes(x=Var1,y=Freq))+geom_bar(stat = "identity", position = "dodge") + labs(x="Pclass")
```

Observamos que la mitad de los pasajeros de primera clase tienen precios mayores
de lo esperado. Sin embargo, para las clases segunda y tercera hay muy poco que tengan outliers por lo tanto podremos reemplazar sus valores por la media del
valor del ticket por cada clase.

```{r echo=TRUE, message=FALSE, warning=FALSE}
#Cojo solo los valores que no sean outliers y calculo la media
people_red_wo_out <- people_red[!(people_red$Fare %in% bpFare$out),]
mean_class <- aggregate(people_red_wo_out$Fare, list(people_red_wo_out$Pclass), mean)
colnames(mean_class) <- c("Pclass", "mean")
#Sustituyo para la clase 2
people_red[(people_red$Fare %in% bpFare$out) & (people_red$Pclass == 2),]$Fare <- mean_class[mean_class$Pclass == 2,]$mean
#Sustituyo para la clase 3
people_red[(people_red$Fare %in% bpFare$out) & (people_red$Pclass == 3),]$Fare <- mean_class[mean_class$Pclass == 3,]$mean
```

Si nos fijamos otra vez en el diagrama de cajas observamos que hay una separación grande entre tickets con valor menor que 200 y mayor que 200, por lo tanto, estos valores también los sustituiremos con la media

```{r echo=TRUE, message=FALSE, warning=FALSE}
#Sustituyo para la clase 1
people_red[(people_red$Fare %in% bpFare$out) & (people_red$Pclass == 1) & (people_red$Fare >= 200),]$Fare <- mean_class[mean_class$Pclass == 1,]$mean
```

******
# Análisis de los datos.
******

## Selección de los grupos de datos

A continuación, Vamos a seleccionar de nuestro conjunto de datos aquellos que pueden resultar más interesantes para investigar y analizar.

```{r echo=TRUE, message=FALSE, warning=FALSE}
#Agrupación por sexo
people_red.male <- people_red[people_red$Sex == "male",]
people_red.female <- people_red[people_red$Sex == "female",]

#Agrupación por embarque
people_red.cherbourg <- people_red[people_red$Embarked == "C",]
people_red.southampton <- people_red[people_red$Embarked == "S",]
people_red.queenstown <- people_red[people_red$Embarked == "Q",]

#Agrupación por clase
people_red.first <- people_red[people_red$Pclass == 1,]
people_red.second <- people_red[people_red$Pclass == 2,]
people_red.third <- people_red[people_red$Pclass == 3,]

```

## Comprobación de normalidad y homogeneidad

### Normalidad

Mirmaos primero la normalidad de todas las variables numéricas. Para ello aplicamos el test de Shapiro-Wilk.


```{r echo=TRUE, message=FALSE, warning=FALSE}
for(c in names(people_red)) {
  if(is.numeric(people_red[[c]])) {
    print(c)
    print(shapiro.test(people_red[[c]]))
  }
}
```

Observamos que el p-valor es muy inferior a 0.05 en todas las variables y rechazamos la hipótesis nula, por lo tanto, no podemos suponer normalidad. 


### Homocedasticidad

Ahora pasaremos a estudiar la homogeneidad de varianzas mediante la aplicación del test de Fligner-Killeen dado que no tenemos normalidad. Estudiaremos la homocedasticidad de Fare y Age según los grupos: la clase del pasajero (Pclass), el lugar de embarque (Embarked) y el sexo (Sex).

```{r echo=TRUE, message=FALSE, warning=FALSE}
#Age
fligner.test(Age ~ as.factor(Pclass), data = people_red)
fligner.test(Age ~ as.factor(Embarked), data = people_red)
fligner.test(Age ~ as.factor(Sex), data = people_red)
```

Vemos que con Age, tanto Embarked como Sex, tienen un p-valor superior a 0,05 y, por lo tanto, no podemos rechazar la hipótesis nula lo que implica homogeneidad en la varianza.

```{r echo=TRUE, message=FALSE, warning=FALSE}
#Fare
fligner.test(Fare ~ as.factor(Pclass), data = people_red)
fligner.test(Fare ~ as.factor(Embarked), data = people_red)
fligner.test(Fare ~ as.factor(Sex), data = people_red)
```

Observamos que para las tres pruebas resulta un p-valor inferior al nivel de significancia (< 0,05). Por lo tanto, se rechaza la hipótesis nula de homocedasticidad y se concluye que la variable Fare presenta varianzas estadísticamente diferentes para los diferentes grupos de Pclass, Embarked y Sex.

## Análisis

### Regresión Logística

En este caso, realizaremos una regresión logística para predecir nuestros datos. Para ello, lo primero que haremos será convertir la variable survived en un factor 0, 1 y la variable PClass en factor también. 

```{r echo=TRUE, message=FALSE, warning=FALSE}
people_red$Survived <- as.factor(people_red$Survived)
people_red$Pclass <- as.factor(people_red$Pclass)
str(people_red)
```

Ahora, vamos a aplicar una regresión logística utilizando todas las variables, tanto cuantitativas como cualitativas. Como no disponemos de conjunto de test, realizamos validación cruzada K-fold sobre el modelo de regresión con 10 iteraciones. Para saber que covariables meter al modelo, debemos mirar si hay variables de confusión, esto es, variables que al meterlas dentro del modelo, cambien significativamente el factor

```{r echo=TRUE, message=FALSE, warning=FALSE}
train_control <- trainControl(method = "cv", number = 10)

# train the model on training set
logist <- train(Survived ~ .,
               data = people_red,
               trControl = train_control,
               method = "glm",
               family=binomial())
summary(logist)
```

Podemos observar aquí como las variables de PClass, Sex, Age, SibSp y Parch son significativas ya que el p-valor proporcionado por el estadístico de Wald es inferior a 0,05. De estos regresores, vamos a ver cuál tiene mayor impacto. Para ello utilizamos el criterio de información de Akaike, es decir, observamos que valor tiene el AIC con cada una de las variables predictoras por separado.
```{r echo=TRUE, message=FALSE, warning=FALSE}
#Pclass
summary(train(Survived ~ Pclass,
                data = people_red,
                trControl = train_control,
                method = "glm",
                family=binomial(),
                metric="Accuracy"))
#Sex
summary(train(Survived ~ Sex,
                data = people_red,
                trControl = train_control,
                method = "glm",
                family=binomial(),
                metric="Accuracy"))
#Age
summary(train(Survived ~ Age,
                data = people_red,
                trControl = train_control,
                method = "glm",
                family=binomial(),
                metric="Accuracy"))
#SibSp
summary(train(Survived ~ Pclass + Sex + SibSp + Parch + Embarked,
                data = people_red,
                trControl = train_control,
                method = "glm",
                family=binomial(),
                metric="Accuracy"))
#Parch
summary(train(Survived ~ Pclass + Sex + SibSp + Parch + Embarked,
                data = people_red,
                trControl = train_control,
                method = "glm",
                family=binomial(),
                metric="Accuracy"))
```

Si comparamos los valores de AIC de cada modelo observamos que el de Sex es el mas bajo luego esa sera la variable más representativa. Por último, creamos la matriz de confusión para ver cuál es el valor predictivo de nuestro modelo.

```{r echo=TRUE, message=FALSE, warning=FALSE}
cm <- confusionMatrix(logist)
VP <- cm$table[1]
FN <- cm$table[2]
FP <- cm$table[3]
VN <- cm$table[4]
sensitivity <- (VP / (VP + FP))
especificity <- (VN / (VN + FP))
cm
print(paste0("La sensibilidad es: ", sensitivity))
print(paste0("La especificidad  es: ", especificity))
```

Observamos que nuestro modelo tiene una precisión decente aunque mejorable. Sobre todo, nuestro modelo identifica bien los registros positivos ya que tiene una sensibilidad alta.

******
# Conclusiones
******

******
# Tabla de contribuciones
******